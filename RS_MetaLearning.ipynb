{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6cd43b-02cb-4a0b-b77e-500afd0ea392",
   "metadata": {},
   "source": [
    "# Recommender Systemas - Morphing and Meatafeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d62b09-d40d-4060-b37c-d3360bc54fee",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115deb01-2d58-4e74-8754-9d0cdf090d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from recommendation import implicit_util\n",
    "from scipy.sparse import csr_matrix\n",
    "import implicit.evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as pltt\n",
    "import seaborn as sns\n",
    "from exploration import exploration_util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c2e5c-95a7-4632-be35-10da90d2b926",
   "metadata": {},
   "source": [
    "## MetaLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32105dfd-d34a-466a-b718-4dfbdcd31f3c",
   "metadata": {},
   "source": [
    "### Space D - Building Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d48e5-345b-47ca-9f1b-939af02d0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_1(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=1))\n",
    "\n",
    "def traj_2(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=2))\n",
    "\n",
    "def traj_3(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=3))\n",
    "\n",
    "def traj_4(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=4))\n",
    "\n",
    "def traj_5(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=5))\n",
    "\n",
    "def traj_6(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=6))\n",
    "\n",
    "def traj_7(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=7))\n",
    "\n",
    "def traj_8(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=8))\n",
    "\n",
    "def traj_9(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=9))\n",
    "\n",
    "def traj_10(df_source, df_target):\n",
    "    return list(swap_rows(df_source, df_target, seed=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183dafb-f27d-4e15-aeb7-b4068144c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_rows(df_source, df_target, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    # Obter uma permutação aleatória dos índices das linhas\n",
    "    indices = np.random.permutation(len(df_source))\n",
    "    df_intermediate = df_source.copy()\n",
    "    for idx in indices:\n",
    "        # Trocar a linha no índice atual com a linha correspondente do dataframe alvo\n",
    "        df_intermediate.iloc[idx] = df_target.iloc[idx]\n",
    "        # Yield retorna o dataframe intermediário após cada troca\n",
    "        yield df_intermediate.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fef64-cbc8-4b29-af51-69973c77f820",
   "metadata": {},
   "source": [
    "### Space MF - Extracting MetaFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ac45f-ae6e-48ca-bfb3-06289caed73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, kurtosis\n",
    "def gini(x):\n",
    "    #fonte: https://stackoverflow.com/a/39513799\n",
    "    #calcula o indice de gini normalizado\n",
    "    mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    rmad = mad / np.mean(x)\n",
    "    g = 0.5 * rmad\n",
    "    return g\n",
    "    \n",
    "def calculate_metafeatures(df):\n",
    "    metafeatures = {}\n",
    "    column_counts = df.count(axis=0).to_numpy()\n",
    "    metafeatures['column.count.entropy'] = entropy(df.count(axis=0))\n",
    "    metafeatures['column.count.gini'] = gini(column_counts)\n",
    "    #metafeatures['column.count.kurtosis'] = kurtosis(df.count(axis=0))\n",
    "    metafeatures['column.count.mean'] = np.mean(df.count(axis=0))\n",
    "    metafeatures['column.mean.entropy'] = entropy(df.mean(axis=0))\n",
    "    metafeatures['row.count.entropy'] = entropy(df.count(axis=1))\n",
    "    #metafeatures['row.count.kurtosis'] = kurtosis(df.count(axis=1))\n",
    "    metafeatures['row.count.max'] = np.max(df.count(axis=1))\n",
    "    metafeatures['nrBin'] = np.sum(df.nunique())\n",
    "    metafeatures['attrConc.mean'] = np.mean(df.var(axis=0))\n",
    "    #metafeatures['attrEnt.mean'] = np.mean(entropy(df, axis=0))\n",
    "    metafeatures['nZeros'] = np.sum(df == 0)\n",
    "    metafeatures['sparsity'] = np.sum(df == 0) / df.size\n",
    "    \n",
    "    return pd.DataFrame(metafeatures, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105be8b-1110-4c04-8a4f-002e8a86868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metafeatures_data(dfs):\n",
    "    metafeatures_list = []\n",
    "    for df in dfs:\n",
    "        metafeatures_df = calculate_metafeatures(df)\n",
    "        metafeatures_list.append(metafeatures_df)\n",
    "    combined_metafeatures_df = pd.concat(metafeatures_list, ignore_index=True)\n",
    "    return combined_metafeatures_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cc5ea-d6b9-4e30-9b1d-5224f3b4fdb7",
   "metadata": {},
   "source": [
    "### Space F - Extracting MetaLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ef30a-1bcf-4174-9631-e15b3a3450af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(df):\n",
    "    #Construçao da matrix (user x recipe x ratings)\n",
    "    user_recipe_matrix = csr_matrix((df['rating'], (df['new_member_id'], df['new_recipe_id'])))\n",
    "    # Test/train split #Alternatively use implicit.evaluation.leave_k_out_split to force each user being in both sets\n",
    "    train_matrix, test_matrix = implicit.evaluation.train_test_split(user_recipe_matrix.tocsr().tocoo())\n",
    "    \n",
    "    # Get users/recipes in the train set (or test set respectively)\n",
    "    train_user, train_recipe = implicit_util.tuple_to_unique(train_matrix.tocsr().nonzero())\n",
    "    test_user, test_recipe = implicit_util.tuple_to_unique(test_matrix.tocsr().nonzero())\n",
    "    \n",
    "    # Executes all models, exception on Windows/Python3.10: nmslib_als, faiss_als\n",
    "    evaluation, recommendations, similar_items, similar_users = implicit_util.train_and_execute_all(train_matrix, test_matrix, train_user, train_recipe, ['nmslib_als', 'faiss_als'], K=10)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd38578-05e6-4729-aa90-99d5cfe1e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melhor_alg(df):\n",
    "    #eval_df = pd.DataFrame(df)\n",
    "    df['media']=df.mean(axis=1) #faz a media dos valores das metricas para cada alg\n",
    "    melhor_algoritmo = df['media'].idxmax()\n",
    "    df['melhor_algoritmo']=df.index==melhor_algoritmo\n",
    "    return melhor_algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060505f3-3c44-4398-afd3-70883fc4fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_metalabels(dfs):\n",
    "    labels=[]\n",
    "    for df in dfs:\n",
    "        evaluations=evaluation(df)\n",
    "        label=melhor_alg(evaluations)\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a558d-d322-4f22-a256-74338330825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metados(df,labels):\n",
    "    df['Algoritmo'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7017c-4967-41a7-a4d4-19d7955abb62",
   "metadata": {},
   "source": [
    "### MetaDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699aa72-ef71-4367-961f-3f418392575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_MetaFeatures(Ds, Dt):\n",
    "    #Trajetorias\n",
    "    intermediates_1 = traj_1(Ds, Dt)\n",
    "    intermediates_2 = traj_2(Ds, Dt)\n",
    "    intermediates_3 = traj_3(Ds, Dt)\n",
    "    intermediates_4 = traj_4(Ds, Dt)\n",
    "    intermediates_5 = traj_5(Ds, Dt)\n",
    "    intermediates_6 = traj_6(Ds, Dt)\n",
    "    intermediates_7 = traj_7(Ds, Dt)\n",
    "    intermediates_8 = traj_8(Ds, Dt)\n",
    "    intermediates_9 = traj_9(Ds, Dt)\n",
    "    intermediates_10 = traj_10(Ds, Dt)\n",
    "    \n",
    "    #Calcular Metafeatures\n",
    "    meafeatures_intermedio1=metafeatures_data(intermediates_1)\n",
    "    meafeatures_intermedio2=metafeatures_data(intermediates_2)\n",
    "    meafeatures_intermedio3=metafeatures_data(intermediates_3)\n",
    "    meafeatures_intermedio4=metafeatures_data(intermediates_4)\n",
    "    meafeatures_intermedio5=metafeatures_data(intermediates_5)\n",
    "    meafeatures_intermedio6=metafeatures_data(intermediates_6)\n",
    "    meafeatures_intermedio7=metafeatures_data(intermediates_7)\n",
    "    meafeatures_intermedio8=metafeatures_data(intermediates_8)\n",
    "    meafeatures_intermedio9=metafeatures_data(intermediates_9)\n",
    "    meafeatures_intermedio10=metafeatures_data(intermediates_10)\n",
    "\n",
    "    #Dataset MetaFeatures sem Metalabels\n",
    "    df_metafeatures = pd.concat([meafeatures_intermedio1, meafeatures_intermedio2, meafeatures_intermedio3,meafeatures_intermedio4,meafeatures_intermedio5,meafeatures_intermedio6,meafeatures_intermedio7,meafeatures_intermedio8,meafeatures_intermedio9,meafeatures_intermedio10], ignore_index=True)\n",
    "    \n",
    "    #Metalabels\n",
    "    labels_intermedio1=obter_metalabels(intermediates_1)\n",
    "    labels_intermedio2=obter_metalabels(intermediates_2)\n",
    "    labels_intermedio3=obter_metalabels(intermediates_3)\n",
    "    labels_intermedio4=obter_metalabels(intermediates_4)\n",
    "    labels_intermedio5=obter_metalabels(intermediates_5)\n",
    "    labels_intermedio6=obter_metalabels(intermediates_6)\n",
    "    labels_intermedio7=obter_metalabels(intermediates_7)\n",
    "    labels_intermedio8=obter_metalabels(intermediates_8)\n",
    "    labels_intermedio9=obter_metalabels(intermediates_9)\n",
    "    labels_intermedio10=obter_metalabels(intermediates_10)\n",
    "    \n",
    "    #juntar labels numa so\n",
    "    df1 = pd.DataFrame(labels_intermedio1, columns=['label'])\n",
    "    df2 = pd.DataFrame(labels_intermedio2, columns=['label'])\n",
    "    df3 = pd.DataFrame(labels_intermedio3, columns=['label'])\n",
    "    df4 = pd.DataFrame(labels_intermedio4, columns=['label'])\n",
    "    df5 = pd.DataFrame(labels_intermedio5, columns=['label'])\n",
    "    df6 = pd.DataFrame(labels_intermedio6, columns=['label'])\n",
    "    df7 = pd.DataFrame(labels_intermedio7, columns=['label'])\n",
    "    df8 = pd.DataFrame(labels_intermedio8, columns=['label'])\n",
    "    df9 = pd.DataFrame(labels_intermedio9, columns=['label'])\n",
    "    df10 = pd.DataFrame(labels_intermedio10, columns=['label'])\n",
    "\n",
    "    # Junta todos os dataframes em um só\n",
    "    df_total = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10], ignore_index=True\n",
    "    \n",
    "    #Dataset MetaFeatures com Metalabels\n",
    "    if len(df_metafeatures) != len(df_total):\n",
    "        raise ValueError(\"O número de linhas de df_metafeatures e df_total deve ser o mesmo\")\n",
    "    df_metafeatures['Alg'] = df_total['label'].values\n",
    "\n",
    "    #Normalizar\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_cols = df_metafeatures.select_dtypes(include='number').columns\n",
    "    df_metafeatures[numeric_cols] = scaler.fit_transform(df_metafeatures[numeric_cols])\n",
    "    \n",
    "    \n",
    "    return df_metafeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366faefb-1136-447b-a9d9-1e8c3415a5f8",
   "metadata": {},
   "source": [
    "## MetaFeatures - Internal Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f33ed-c4ce-4a3f-8204-f7f5b070288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='C:\\\\Users\\\\beatr\\\\Desktop\\\\Estágio\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fcb79b-0081-4934-ab07-623a61ee6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummus_reviews=pd.read_csv(dir+'\\\\pp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8272f39-206b-4f93-989e-6446e11bd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=hummus_reviews[['new_member_id','new_recipe_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775406be-95f3-4b11-9cae-dd4399c87871",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = reviews.sample(frac=0.5, random_state=42)  \n",
    "Dt = reviews.drop(Ds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98bb3b-face-40fa-9ace-e0c1dcc38ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hummus_metafeatures=df_MetaFeatures(Ds,Dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298371ef-b4c3-4d9d-9ebb-28c989aab1f4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89b8c0-ac1a-45b8-94f6-04e9f494f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hummus_metafeatures.drop(columns=['Alg'])\n",
    "y = hummus_metafeatures['Alg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy do Modelo no Conjunto de Teste:\", accuracy)me y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be21ba-5822-4a02-a8d7-0d14ffcb3655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f662a01-108b-4aae-a97a-51bb3192af72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
